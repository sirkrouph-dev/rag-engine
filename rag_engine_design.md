# RAG Engine â€” Modular Retrieval-Augmented Generation Framework

## ğŸš€ Vision

**RAG Engine** is a plug-n-play, deeply configurable framework to build Retrieval-Augmented Generation (RAG) pipelines using configuration-as-code. It allows developers to customize and orchestrate every step of the RAG stack â€” from data loading to prompting â€” with multiple interfaces (CLI, API, UI).

---

## ğŸ§© Design Principles

| Principle           | Description                                                                     |
| ------------------- | ------------------------------------------------------------------------------- |
| **Modularity**      | Each pipeline stage (loader, chunker, embedder, vectorstore, etc.) is pluggable |
| **Config-as-Code**  | Full YAML-based configuration with Pydantic schema validation                   |
| **Multi-Interface** | CLI, FastAPI (REST), and Streamlit/Gradio interface support                     |
| **Extensibility**   | User-defined modules and plugin system                                          |
| **Ease of Use**     | Minimal CLI commands and smart defaults                                         |

---

## ğŸ“¦ Project Structure

```plaintext
rag-engine/
â”œâ”€â”€ rag_engine/
â”‚   â”œâ”€â”€ core/                # Core logic and base interfaces
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract classes/interfaces
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â”œâ”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ vectorstore.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”œâ”€â”€ prompting.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py
â”‚   â”‚   â””â”€â”€ registry.py      # Dynamic component loader
â”‚   â”œâ”€â”€ plugins/             # Optional user-defined modules
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â”œâ”€â”€ cli.py           # Typer-based CLI
â”‚   â”‚   â”œâ”€â”€ api.py           # FastAPI REST server
â”‚   â”‚   â””â”€â”€ ui.py            # Streamlit or Gradio interface
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ schema.py        # Pydantic config models
â”‚   â”‚   â””â”€â”€ loader.py        # Config parser and validator
â”‚   â””â”€â”€ __main__.py          # CLI entry point
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ example_config.yml
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ quickstart.md
â”œâ”€â”€ tests/
â”œâ”€â”€ README.md
â””â”€â”€ pyproject.toml / setup.py
```

---

## ğŸ”§ Configuration (YAML Example)

```yaml
documents:
  - type: pdf
    path: ./docs/tech_guide.pdf

chunking:
  method: recursive
  max_tokens: 512
  overlap: 50

embedding:
  model: openai
  api_key: ${OPENAI_API_KEY}

vectorstore:
  provider: chroma
  persist_directory: ./vector_store

retrieval:
  top_k: 4

prompting:
  system_prompt: >
    You are a technical assistant. Answer clearly and concisely.

llm:
  provider: openai
  model: gpt-4
  temperature: 0.3

output:
  method: console
```

---

## ğŸ§  Core Components

- `Loader`: PDF, Markdown, Web, Notion, etc.
- `Chunker`: Sentence, recursive, fixed-size
- `Embedder`: OpenAI, HuggingFace, InstructorXL
- `Vectorstore`: Chroma, FAISS, Pinecone, Weaviate
- `Retriever`: Top-K, MMR, filters
- `Prompting`: Template engine (Jinja2, etc.)
- `LLM`: OpenAI, Anthropic, Local LLMs (Ollama)
- `Pipeline`: Glue logic
- `Evaluation`: Response quality grading (optional)

---

## ğŸ§ª CLI Commands

```bash
# Scaffold new RAG project
rag-engine init

# Build vector DB from config
rag-engine build --config configs/example_config.yml

# Chat with your data
rag-engine chat --config configs/example_config.yml

# Serve API and/or UI
rag-engine serve --api
rag-engine serve --ui
```

---

## ğŸ§‘â€ğŸ’» Stretch Goals (Future Enhancements)

- âœ… Versioned pipelines
- âœ… Plugin support for user-defined chunkers/retrievers
- âœ… LLM cost estimation
- âœ… CI test runner for prompts
- âœ… Eval mode using GPT-based graders
- âœ… Docker image for full stack
- âœ… Web dashboard for monitoring retrieval + chat

---

## ğŸ›  Tech Stack

| Layer         | Tool                                   |
| ------------- | -------------------------------------- |
| CLI           | [`Typer`](https://typer.tiangolo.com/) |
| Config        | `YAML` + `Pydantic`                    |
| LLM/Embedding | OpenAI, Claude, Ollama                 |
| Vector DB     | Chroma, FAISS, Pinecone                |
| API           | FastAPI                                |
| UI (optional) | Streamlit or Gradio                    |
| Docs          | Markdown / Sphinx / MkDocs             |

---

## âœ… Next Steps

1. Setup virtual environment & install dependencies:

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

2. Run CLI to scaffold example:

   ```bash
   rag-engine init
   rag-engine build --config configs/example_config.yml
   ```

3. Start experimenting:

   ```bash
   rag-engine chat
   ```

---

## ğŸ§ª Example Prompt Engineering Flow

1. Write prompt templates in `prompts/`
2. Reference them in YAML config
3. Evaluate with sample questions via `rag-engine evaluate`
4. Log results to CSV or visual dashboard

---

## ğŸ¤ Contribute

- All modules follow an interface pattern.
- To add a new `embedder`, simply implement the `BaseEmbedder` class in `plugins/`.
- Contributions welcome via PRs or plugins!

---

## ğŸ“œ License

MIT (you can change this)

